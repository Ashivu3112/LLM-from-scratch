{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODHCplXH4Fm33T3Vp8ZtAM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ISbHedAuK0fB","executionInfo":{"status":"ok","timestamp":1762701785749,"user_tz":-330,"elapsed":31,"user":{"displayName":"Ashish Biswal","userId":"03902015277986563515"}},"outputId":"db3b8eb9-8e1c-4b83-b04a-10c32ed0d730"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6, 5])\n"]}],"source":["inputs = torch.tensor([\n","  [-0.12,  0.25,  0.09, -0.03,  0.18],  # life\n","  [ 0.07,  0.44, -0.16,  0.09,  0.03],  # is\n","  [ 0.33, -0.09,  0.17, -0.27,  0.48],  # a\n","  [-0.41,  0.22,  0.31,  0.12,  0.09],  # journey\n","  [ 0.29, -0.34, -0.05,  0.47, -0.08],  # not\n","  [-0.08,  0.12, -0.24,  0.41,  0.06]   # destination\n","])\n","print(inputs.shape)"]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"MoXqasSjL6i-","executionInfo":{"status":"ok","timestamp":1762701433703,"user_tz":-330,"elapsed":5610,"user":{"displayName":"Ashish Biswal","userId":"03902015277986563515"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class SimplifiedAttention(torch.nn.Module):\n","    def __init__(self):\n","      super().__init__()\n","      self.W_q = None\n","      self.W_k = None\n","      self.W_v = None\n","\n","    def forward(self, x, bias = False):\n","      self.W_q = torch.nn.Linear(5, 3, bias=bias)\n","      self.W_k = torch.nn.Linear(5, 3, bias=bias)\n","      self.W_v = torch.nn.Linear(5, 3, bias=bias)\n","      print(\"W_q: \", self.W_q.weight.shape)\n","      print(\"W_k: \", self.W_k.weight.shape)\n","      print(\"W_v: \", self.W_v.weight.shape)\n","\n","      q = self.W_q(x)\n","      k = self.W_k(x)\n","      v = self.W_v(x)\n","\n","      print(\"q: \", q.shape)\n","      print(\"k: \", k.shape)\n","      print(\"v: \", v.shape)\n","\n","      attention_scores = q @ k.T\n","      print(\"attention_scores: \", attention_scores.shape)\n","      attention_weights = torch.nn.functional.softmax(attention_scores / attention_scores.shape[-1] ** 0.5, dim=-1)\n","      context_vector = attention_weights @ v\n","      print(\"context_vector: \", context_vector.shape)\n","      return context_vector\n"],"metadata":{"id":"q8Udw9D6MUQE","executionInfo":{"status":"ok","timestamp":1762702596600,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ashish Biswal","userId":"03902015277986563515"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["sa = SimplifiedAttention()\n","print(sa(inputs)) # internally calls the nn.Module's forward method"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pwt8xnGOjKo","executionInfo":{"status":"ok","timestamp":1762702618027,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ashish Biswal","userId":"03902015277986563515"}},"outputId":"3d9a65b9-0921-4b87-e525-98dab2320604"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["W_q:  torch.Size([3, 5])\n","W_k:  torch.Size([3, 5])\n","W_v:  torch.Size([3, 5])\n","q:  torch.Size([6, 3])\n","k:  torch.Size([6, 3])\n","v:  torch.Size([6, 3])\n","attention_scores:  torch.Size([6, 6])\n","context_vector:  torch.Size([6, 3])\n","tensor([[-0.1218, -0.0199, -0.0004],\n","        [-0.1222, -0.0206, -0.0011],\n","        [-0.1211, -0.0186,  0.0010],\n","        [-0.1218, -0.0197, -0.0001],\n","        [-0.1202, -0.0174,  0.0023],\n","        [-0.1213, -0.0191,  0.0005]], grad_fn=<MmBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gkUFofAlPeKe"},"execution_count":null,"outputs":[]}]}